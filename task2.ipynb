{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't change this cell\n",
    "import mytorch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "FILE_PATH = './wdbc.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_21</th>\n",
       "      <th>Feature_22</th>\n",
       "      <th>Feature_23</th>\n",
       "      <th>Feature_24</th>\n",
       "      <th>Feature_25</th>\n",
       "      <th>Feature_26</th>\n",
       "      <th>Feature_27</th>\n",
       "      <th>Feature_28</th>\n",
       "      <th>Feature_29</th>\n",
       "      <th>Feature_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.372583</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.483918</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Diagnosis   Feature_1   Feature_2   Feature_3    Feature_4  \\\n",
       "count  569.000000  569.000000  569.000000  569.000000   569.000000   \n",
       "mean     0.372583   14.127292   19.289649   91.969033   654.889104   \n",
       "std      0.483918    3.524049    4.301036   24.298981   351.914129   \n",
       "min      0.000000    6.981000    9.710000   43.790000   143.500000   \n",
       "25%      0.000000   11.700000   16.170000   75.170000   420.300000   \n",
       "50%      0.000000   13.370000   18.840000   86.240000   551.100000   \n",
       "75%      1.000000   15.780000   21.800000  104.100000   782.700000   \n",
       "max      1.000000   28.110000   39.280000  188.500000  2501.000000   \n",
       "\n",
       "        Feature_5   Feature_6   Feature_7   Feature_8   Feature_9  ...  \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  ...   \n",
       "mean     0.096360    0.104341    0.088799    0.048919    0.181162  ...   \n",
       "std      0.014064    0.052813    0.079720    0.038803    0.027414  ...   \n",
       "min      0.052630    0.019380    0.000000    0.000000    0.106000  ...   \n",
       "25%      0.086370    0.064920    0.029560    0.020310    0.161900  ...   \n",
       "50%      0.095870    0.092630    0.061540    0.033500    0.179200  ...   \n",
       "75%      0.105300    0.130400    0.130700    0.074000    0.195700  ...   \n",
       "max      0.163400    0.345400    0.426800    0.201200    0.304000  ...   \n",
       "\n",
       "       Feature_21  Feature_22  Feature_23   Feature_24  Feature_25  \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    16.269190   25.677223  107.261213   880.583128    0.132369   \n",
       "std      4.833242    6.146258   33.602542   569.356993    0.022832   \n",
       "min      7.930000   12.020000   50.410000   185.200000    0.071170   \n",
       "25%     13.010000   21.080000   84.110000   515.300000    0.116600   \n",
       "50%     14.970000   25.410000   97.660000   686.500000    0.131300   \n",
       "75%     18.790000   29.720000  125.400000  1084.000000    0.146000   \n",
       "max     36.040000   49.540000  251.200000  4254.000000    0.222600   \n",
       "\n",
       "       Feature_26  Feature_27  Feature_28  Feature_29  Feature_30  \n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  \n",
       "mean     0.254265    0.272188    0.114606    0.290076    0.083946  \n",
       "std      0.157336    0.208624    0.065732    0.061867    0.018061  \n",
       "min      0.027290    0.000000    0.000000    0.156500    0.055040  \n",
       "25%      0.147200    0.114500    0.064930    0.250400    0.071460  \n",
       "50%      0.211900    0.226700    0.099930    0.282200    0.080040  \n",
       "75%      0.339100    0.382900    0.161400    0.317900    0.092080  \n",
       "max      1.058000    1.252000    0.291000    0.663800    0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#don't change this cell\n",
    "column_names = [\"ID\", \"Diagnosis\"] + [f\"Feature_{i}\" for i in range(1, 31)]\n",
    "df = pd.read_csv(FILE_PATH, header=None, names=column_names, usecols=range(1, 32))\n",
    "\n",
    "df[\"Diagnosis\"] = df[\"Diagnosis\"].map({\"M\": 1, \"B\": 0})\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell\n",
    "X = df.drop(columns=[\"Diagnosis\"]).values\n",
    "y = df[\"Diagnosis\"].values\n",
    "\n",
    "Xy = np.concatenate((X, y.reshape(-1, 1)), axis=1)\n",
    "np.random.shuffle(Xy)\n",
    "\n",
    "n_data = Xy.shape[0]\n",
    "n_train = int(0.8 * n_data)\n",
    "n_test = n_data - n_train\n",
    "\n",
    "train = Xy[:n_train, :]\n",
    "test = Xy[n_train:, :]\n",
    "\n",
    "X_train = train[:, :-1]\n",
    "y_train = train[:, -1].reshape(-1, 1)\n",
    "X_test = test[:, :-1]\n",
    "y_test = test[:, -1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, x_train, y_train, batch_size, shuffle=True):\n",
    "        self.x_train = np.array(x_train)\n",
    "        self.y_train = np.array(y_train)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.x_train))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        self.current_index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_index >= len(self.x_train):\n",
    "            self.current_index = 0\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(self.indexes)\n",
    "            raise StopIteration\n",
    "        if self.current_index == 0:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        \n",
    "        batch_indexes = self.indexes[self.current_index:self.current_index + self.batch_size]\n",
    "        batch_x = self.x_train[batch_indexes]\n",
    "        batch_y = self.y_train[batch_indexes]\n",
    "        self.current_index += self.batch_size\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.x_train) + self.batch_size - 1) // self.batch_size  # Ceiling division\n",
    "\n",
    "train_loader = DataLoader(X_train, y_train, 64)\n",
    "test_loader = DataLoader(X_test, y_test, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "from mytorch.activation import *\n",
    "from  mytorch.layer import *\n",
    "\n",
    "\n",
    "class MLP(mytorch.Model):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.l1 = Linear(input_size, 100, need_bias=True)\n",
    "        self.l2 = Linear(100, 200, need_bias=True)\n",
    "        self.l3 = Linear(200, 50, need_bias=True)\n",
    "        self.l4 = Linear(50, 1, need_bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = relu(self.l1(x))\n",
    "        x = relu(self.l2(x))\n",
    "        x = relu(self.l3(x))\n",
    "        x = sigmoid(self.l4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "import mytorch.loss\n",
    "import mytorch.loss.mse\n",
    "import mytorch.optimizer\n",
    "\n",
    "\n",
    "input_size = 30\n",
    "model = MLP(input_size)\n",
    "\n",
    "\n",
    "criterion = mytorch.loss.MeanSquaredError\n",
    "optimizer = mytorch.optimizer.SGD(model.parameters(), learning_rate=0.001)\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'Tensor' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[1;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m---> 20\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/mnt/DE0A83560A832B1B/UNI/T6/Computational Intelgence/P1/mytorch/loss/mse.py:10\u001b[0m, in \u001b[0;36mMeanSquaredError\u001b[0;34m(preds, actual)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m=\u001b[39m sqDiff\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      9\u001b[0m num \u001b[38;5;241m=\u001b[39m Tensor(np\u001b[38;5;241m.\u001b[39marray(np\u001b[38;5;241m.\u001b[39mprod(sqDiff\u001b[38;5;241m.\u001b[39mshape), dtype\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64))\n\u001b[0;32m---> 10\u001b[0m mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;129;01mor\u001b[39;00m actual\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m     12\u001b[0m     mse\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/DE0A83560A832B1B/UNI/T6/Computational Intelgence/P1/mytorch/tensor.py:79\u001b[0m, in \u001b[0;36mTensor.div\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdiv\u001b[39m(\u001b[38;5;28mself\u001b[39m, other) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_div\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/DE0A83560A832B1B/UNI/T6/Computational Intelgence/P1/mytorch/tensor.py:287\u001b[0m, in \u001b[0;36m_div\u001b[0;34m(t1, t2)\u001b[0m\n\u001b[1;32m    284\u001b[0m denominator \u001b[38;5;241m=\u001b[39m t2\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64) \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(t2\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m t2\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Compute division\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mt1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdenominator\u001b[49m\n\u001b[1;32m    288\u001b[0m requires_grad \u001b[38;5;241m=\u001b[39m t1\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;129;01mor\u001b[39;00m t2\u001b[38;5;241m.\u001b[39mrequires_grad\n\u001b[1;32m    289\u001b[0m depends_on \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'Tensor' and 'float'"
     ]
    }
   ],
   "source": [
    "train_accuracy_list= []\n",
    "test_accuracy_list= []\n",
    "\n",
    "#TODO\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total=0\n",
    "    corrects= 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        # get the inputs\n",
    "        inputs = mytorch.Tensor(inputs)\n",
    "        labels = mytorch.Tensor(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data.item() # ?\n",
    "        total += labels.data.size # ?\n",
    "        predicted = (outputs.data > 0.5)\n",
    "        corrects += (predicted == labels.data).sum().item()\n",
    "\n",
    "    accuracy= corrects / total\n",
    "    train_accuracy_list.append(accuracy)\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {(running_loss / len(train_loader)):.4f}, Acurracy= {accuracy:.4f}\")\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = mytorch.Tensor(inputs)\n",
    "        labels = mytorch.Tensor(labels)\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs.data > 0.5) # ?\n",
    "        correct += (predicted == labels.data).sum().item() # ?\n",
    "        total += labels.data.size\n",
    "\n",
    "    accuracy = correct / total\n",
    "    test_accuracy_list.append(accuracy)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, NUM_EPOCHS+1), train_accuracy_list, marker='o', linestyle='-', color='b', label=\"Train Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training Accuracy Over Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, NUM_EPOCHS+1), test_accuracy_list, marker='s', linestyle='-', color='g', label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Test Accuracy Over Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
